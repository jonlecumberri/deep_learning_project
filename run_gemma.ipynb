{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIIrXRZAbJxG",
        "outputId": "6c8b2706-ec74-4bee-ec7c-14d6548f3db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.6.1)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.6.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2025.6.1)\n",
            "Requirement already satisfied: torch<=2.7.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.7.0)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.0.30)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.46.0)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.9.24)\n",
            "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.52.4)\n",
            "Requirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.7.0)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.18.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.15.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.4)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.33.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.22.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (1.1.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (1.11.1.6)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth) (0.21.1)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.6.1->unsloth) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.6.1->unsloth) (11.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.6.1->unsloth) (0.19.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<=2.7.0,>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.7.0,>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.17.0)\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-slg_9pqu/unsloth_3a105e5f7b6e46eeb5b613eb79cb65df\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-slg_9pqu/unsloth_3a105e5f7b6e46eeb5b613eb79cb65df\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit c1b73fa8836aa7e8b9ee13d748369f8f61e1fac5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install Unsloth and dependencies\n",
        "!pip install unsloth\n",
        "!pip install --upgrade --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keTPsYDabUSg",
        "outputId": "cb2ee1be-18c9-47b2-e6c3-2d2ba10d6a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import logging\n",
        "import warnings\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "\n",
        "# ===========================\n",
        "# Setup\n",
        "# ===========================\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
        "BASE_DIR = \"/content\"  # Override HOME for Colab\n",
        "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"data_huang_devansh_processed_equal.csv\")\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"results\", \"gemma_results\")\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# ===========================\n",
        "# Suppress Warnings\n",
        "# ===========================\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec_pxouQba6O",
        "outputId": "465b24be-06f7-4831-8e22-27d7a2fae87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: /content/data/data_huang_devansh_processed_equal.csv\n",
            "Full dataset size: 249954\n",
            "Using last 30%: 2500 samples\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Load Data (last 30%)\n",
        "# ===========================\n",
        "print(f\"Loading data from: {DATA_PATH}\")\n",
        "raw_rows = []\n",
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        text = (row.get(\"Content\") or \"\").strip()\n",
        "        label = (row.get(\"normalized_label\") or row.get(\"Label\") or \"\").strip()\n",
        "        if text and label in {\"0\", \"1\"}:\n",
        "            raw_rows.append((text, int(label)))\n",
        "\n",
        "df = pd.DataFrame(raw_rows, columns=[\"text\", \"label\"])\n",
        "print(f\"Full dataset size: {len(df)}\")\n",
        "\n",
        "start_idx = int(len(df) * 0.7)\n",
        "df = df.iloc[start_idx:].reset_index(drop=True)\n",
        "print(f\"Using last 30%: {len(df)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y4vYsHxHbiCS"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Instruction template\n",
        "# ===========================\n",
        "base_instruction = (\n",
        "    \"You are a content moderation assistant. Classify each text as Hate '1' or No Hate '0'. Reply only with the number.\\n\\n\"\n",
        ")\n",
        "\n",
        "fs_instruction = (\n",
        "    \"You are a content moderation assistant. Classify each text as Hate '1' or No Hate '0'. \"\n",
        "    \"Reply only with the number.\\n\\n\"\n",
        "    \"Example 1:\\n\"\n",
        "    \"Just wanted to let you know you had 2 imposters ( (talk) \\\"\\\"\\\"\\n0\\n\\n\"\n",
        "    \"Example 2:\\n\"\n",
        "    \"thanking you yin... @user tranquil & beautiful friday & #weekend to you üôÇüñêüèΩüòé\\n0\\n\\n\"\n",
        "    \"Example 3:\\n\"\n",
        "    \"Radiant: What does Userfy mean? What is VfD?\\n0\\n\\n\"\n",
        "    \"Example 4:\\n\"\n",
        "    \"dead c o o n s is a good thing\\n1\\n\\n\"\n",
        "    \"Example 5:\\n\"\n",
        "    \"\\\"You are a fool. Hispanics are hispanics are hispanic to the bone. ... conservatives fools.\\\"\\n1\\n\\n\"\n",
        "    \"Example 6:\\n\"\n",
        "    \"\\\"DEAR GILLIAM, YOU PIECE OF SHIZZ  YOU THINK YOU KNOW POKEMON? ...\\\"\\n1\\n\\n\"\n",
        "    \"Example 7:\\n\"\n",
        "    \"its been merged, but how to delete the other article? Shall I have a redirect?\\n0\\n\\n\"\n",
        "    \"Example 8:\\n\"\n",
        "    \"LOL that meme you shared was hilarious, thanks for the laugh!\\n0\\n\\n\"\n",
        "    \"Now classify:\\n\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aehaUxjibsKc",
        "outputId": "affec3dd-4edf-49e5-c200-197dc34338d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.6.1: Fast Gemma3 patching. Transformers: 4.52.4.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Load model and tokenizer\n",
        "# ===========================\n",
        "model_name = \"unsloth/gemma-3-1b-it-bnb-4bit\"\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=8192,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qQ4SkWxTbyu0"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Inference function\n",
        "# ===========================\n",
        "import gc\n",
        "\n",
        "def run_inference(df_subset, instruction, few_shot=False, batch_size=128):\n",
        "    preds = []\n",
        "    if few_shot:\n",
        "        # sample 3 hate and 3 no-hate examples\n",
        "        hate_ex = df[df.label == 1].head(3)\n",
        "        no_ex   = df[df.label == 0].head(3)\n",
        "        examples = pd.concat([hate_ex, no_ex]).sample(frac=1, random_state=42)\n",
        "        ex_prompt = \"\"\n",
        "        for idx, row in enumerate(examples.itertuples(), 1):\n",
        "            ex_prompt += f\"Example {idx}:\\n{row.text}\\n{row.label}\\n\"\n",
        "        prompt_prefix = instruction + ex_prompt + \"Now classify:\\n\"\n",
        "    else:\n",
        "        prompt_prefix = instruction\n",
        "\n",
        "    texts = df_subset.text.tolist()\n",
        "    num_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in tqdm(range(num_batches), desc=\"Batched inference\"):\n",
        "        batch_texts = texts[i*batch_size:(i+1)*batch_size]\n",
        "        prompts     = [prompt_prefix + t for t in batch_texts]\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024,\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out_ids = model.generate(\n",
        "                input_ids=inputs.input_ids,\n",
        "                attention_mask=inputs.attention_mask,\n",
        "                max_new_tokens=5,\n",
        "                use_cache=True,\n",
        "            )\n",
        "\n",
        "        decoded_batch = tokenizer.batch_decode(out_ids, skip_special_tokens=True)\n",
        "        for decoded in decoded_batch:\n",
        "            p = decoded.splitlines()[-1].strip()\n",
        "            preds.append(int(p) if p in {\"0\", \"1\"} else None)\n",
        "\n",
        "        # ‚Äî‚Äî cleanup to free CUDA memory ‚Äî‚Äî\n",
        "        del inputs, out_ids, decoded_batch, prompts, batch_texts\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhsHf74Ob36I",
        "outputId": "e54495ea-3d0c-43fa-eee4-a5993f84669f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batched inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [01:49<00:00,  5.47s/it]\n",
            "Batched inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [02:33<00:00,  7.67s/it]\n",
            "Batched inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [01:12<00:00,  3.63s/it]\n",
            "Batched inference:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [02:23<00:07,  7.65s/it]"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Run experiments across seeds\n",
        "# ===========================\n",
        "seeds = [42, 123, 456, 789, 101112]\n",
        "for seed in seeds:\n",
        "    df_seed = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "    # Zero‚Äêshot\n",
        "    zs_preds = run_inference(df_seed, base_instruction, few_shot=False)\n",
        "    df_seed['pred_zs'] = zs_preds\n",
        "    eval_zs = df_seed.dropna(subset=['pred_zs'])\n",
        "    acc_zs = accuracy_score(eval_zs.label, eval_zs.pred_zs)\n",
        "    f1_zs_h = f1_score(eval_zs.label, eval_zs.pred_zs, pos_label=1)\n",
        "    f1_zs_n = f1_score(eval_zs.label, eval_zs.pred_zs, pos_label=0)\n",
        "    pd.DataFrame([{\n",
        "        'accuracy':  acc_zs,\n",
        "        'f1_Hate':   f1_zs_h,\n",
        "        'f1_NoHate': f1_zs_n\n",
        "    }]).to_csv(\n",
        "        os.path.join(RESULTS_DIR, f\"gemma_base_zs_metrics_seed{seed}.csv\"),\n",
        "        index=False\n",
        "    )\n",
        "\n",
        "    # Few‚Äêshot with fixed examples\n",
        "    fs_preds = run_inference(df_seed, fs_instruction, few_shot=False)\n",
        "    df_seed['pred_fs'] = fs_preds\n",
        "    eval_fs = df_seed.dropna(subset=['pred_fs'])\n",
        "    acc_fs  = accuracy_score(eval_fs.label, eval_fs.pred_fs)\n",
        "    f1_fs_h = f1_score(eval_fs.label, eval_fs.pred_fs, pos_label=1)\n",
        "    f1_fs_n = f1_score(eval_fs.label, eval_fs.pred_fs, pos_label=0)\n",
        "    pd.DataFrame([{\n",
        "        'accuracy':  acc_fs,\n",
        "        'f1_Hate':   f1_fs_h,\n",
        "        'f1_NoHate': f1_fs_n\n",
        "    }]).to_csv(\n",
        "        os.path.join(RESULTS_DIR, f\"gemma_base_fs_metrics_seed{seed}.csv\"),\n",
        "        index=False\n",
        "    )\n",
        "\n",
        "    # free any residual GPU memory between seeds\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"Experiments complete.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
